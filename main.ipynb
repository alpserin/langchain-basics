{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load our OpenAI api key from the env file\n",
    "OPENAI_KEY = os.getenv('OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Maharaja's Palace\" \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize our model with 0.6 temperature\n",
    "llm = OpenAI(temperature=0.6, api_key=OPENAI_KEY)\n",
    "\n",
    "# Ask a question to the model, and store the response in 'name'\n",
    "name = llm(\"I want to open a restaurant for Indian food. Suggest a fancy name for this.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Italian food. Suggest a fancy name for this.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We dont want to change our prompt everytime for different restaurant themes\n",
    "# To solve this, we will create a 'Prompt Template'\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cuisine=\"Italian\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"The Stateside Bistro\"'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will create a chain, which will enable us to use our model with the template we created\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run(\"American\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to create a restaurant menu from the restaurant name generated by the model?\n",
    "# We will use 'Simple Sequential Chain' for this. \n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = \"\"\"Give me a comma seperated text that has menu items for the restaurant named {restaurant_name}.\"\"\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Smoked BBQ Ribs, Fried Chicken Platter, Pulled Pork Sandwich, Mac and Cheese, Collard Greens, Fried Green Tomatoes, Shrimp Po' Boy, Cajun Jambalaya, Fried Catfish, Chicken and Waffles\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# Create Simple Sequential Chain\n",
    "chain = SimpleSequentialChain(chains= [name_chain, food_items_chain])\n",
    "response = chain.run(\"American\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Simple Sequential Chain we only get 1 output, which is the menu items list. But we want to get the restaurant name too.\n",
    "# We will use Sequential Chain for this.\n",
    "llm = OpenAI(temperature=0.7, api_key=OPENAI_KEY)\n",
    "\n",
    "# Chain 1: Restaurant Name\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
    "\n",
    "# Chain 2: Menu Items\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = \"\"\"Give me a comma seperated text that has menu items for the restaurant named {restaurant_name}.\"\"\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Italian',\n",
       " 'restaurant_name': '\\n\\n\"Bella Cucina Trattoria\"',\n",
       " 'menu_items': '\\n\\n\"Antipasto, Insalata Caprese, Bruschetta, Gnocchi, Lasagna, Fettuccine Alfredo, Chicken Parmigiana, Veal Marsala, Shrimp Scampi, Grilled Salmon, Tiramisu, Cannoli\"'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# Create Sequential Chain\n",
    "chain = SequentialChain(\n",
    "    chains= [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', 'menu_items']\n",
    ")\n",
    "\n",
    "chain({'cuisine':'Italian'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
